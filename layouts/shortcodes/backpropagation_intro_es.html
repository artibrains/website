<link rel="stylesheet" href="/css/unified-demos.css">

<div class="medical-context">
    <h2> Contexto M茅dico: Entrenando un "Ojo" Cl铆nico Artificial</h2>
    <div class="medical-scenario">
        <div class="scenario-text">
            <p><strong>Imagina:</strong> Est谩s entrenando una red neuronal para detectar signos de retinopat铆a diab茅tica
                en im谩genes de fondo de ojo. La red debe aprender a distinguir patrones sutiles que un ojo humano podr铆a
                pasar por alto.</p>
            <p class="highlight">Cuando la red clasifica una imagen incorrectamente, Backpropagation act煤a como un
                "supervisor experto". Le indica a la red qu茅 "neuronas" y conexiones interpretaron mal la imagen,
                permitiendo que se ajusten para no cometer el mismo error en el futuro y, con el tiempo, desarrollar un
                "ojo" cl铆nico artificial altamente preciso.</p>
        </div>
    </div>
</div>

<div id="app-explanation">
    <p class="intro">La <strong>Retropropagaci贸n (Backpropagation)</strong> es el motor de aprendizaje de las redes
        neuronales. Funciona como un sistema de "asignaci贸n de responsabilidades": cuando la red comete un error, este
        algoritmo calcula exactamente qu茅 conexiones internas (pesos) contribuyeron al fallo y las ajusta en la
        direcci贸n correcta. Este proceso iterativo de predicci贸n, c谩lculo de error y ajuste es lo que permite a la red
        refinar su "conocimiento" y volverse cada vez m谩s precisa.</p>

    <div class="how-it-works">
        <h2>驴C贸mo aprende la red de sus errores?</h2>
        <div class="explanation-columns">
            <div class="column">
                <h3>1. Predicci贸n y C谩lculo del Error</h3>
                <p>La red procesa los datos de entrada (la imagen) a trav茅s de sus capas para generar una predicci贸n.
                    Luego, se compara esta predicci贸n con el resultado correcto para cuantificar el error total.</p>
            </div>
            <div class="column">
                <h3>2. Retropropagaci贸n de la "Culpa"</h3>
                <p>El error se propaga hacia atr谩s, desde la salida hasta la entrada, calculando cu谩nto "contribuy贸"
                    cada neurona y conexi贸n al error final. A esta medida se le llama gradiente o delta (未).</p>
            </div>
            <div class="column">
                <h3>3. Ajuste de Pesos y Aprendizaje</h3>
                <p>Las conexiones (pesos) se ajustan ligeramente en funci贸n de su "culpa" para reducir el error en la
                    pr贸xima iteraci贸n. La tasa de aprendizaje (畏) controla la magnitud de este ajuste.</p>
            </div>
        </div>
    </div>
</div>